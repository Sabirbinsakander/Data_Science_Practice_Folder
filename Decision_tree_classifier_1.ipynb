{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONFN3x3vVhmZpQSt+ike7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabirbinsakander/Data_Science_Practice_Folder/blob/main/Decision_tree_classifier_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None, klass=None):\n",
        "        self.feat_idx = feature # Renamed to feature to match the parameter name\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.klass = klass\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, tree=None, max_depth=None, min_sample_sz=None):\n",
        "        self.tree = tree\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_sz = min_sample_sz\n",
        "\n",
        "    def build_tree(self, dataset, depth=0):\n",
        "        x, y = dataset[:, :-1], dataset[:, -1]\n",
        "        num_samples, num_feats = x.shape\n",
        "\n",
        "        label_count = np.unique(y).shape[0]\n",
        "\n",
        "        # Termination conditions for recursion\n",
        "        if depth >= self.max_depth or num_samples < self.min_samples_sz or label_count == 1:\n",
        "            return Node(klass=self.major_class(y))\n",
        "\n",
        "        max_gain = -1\n",
        "        left_data, right_data, best_feat, best_threshold = None, None, None, None\n",
        "\n",
        "        # Find the best split\n",
        "        for feat_idx in range(num_feats):\n",
        "            feat_values = np.unique(dataset[:, feat_idx])\n",
        "            for value in feat_values:\n",
        "                left, right = self.split_data(dataset, feat_idx, value)\n",
        "                if left.shape[0] > 0 and right.shape[0] > 0:\n",
        "                    y_left, y_right = left[:, -1], right[:, -1]\n",
        "                    ig = self.info_gain(y, y_left, y_right)\n",
        "                    if ig > max_gain:\n",
        "                        max_gain = ig\n",
        "                        left_data, right_data = left, right\n",
        "                        best_feat, best_threshold = feat_idx, value\n",
        "\n",
        "        # If no split provides information gain, return a leaf node\n",
        "        if max_gain <= 0:\n",
        "             return Node(klass=self.major_class(y))\n",
        "\n",
        "\n",
        "        # Recursively build subtrees\n",
        "        left_subtree = self.build_tree(left_data, depth + 1)\n",
        "        right_subtree = self.build_tree(right_data, depth + 1)\n",
        "\n",
        "        return Node(feature=best_feat, threshold=best_threshold, left=left_subtree, right=right_subtree)\n",
        "\n",
        "\n",
        "    def info_gain(self, parent, l_child, r_child):\n",
        "        lw = l_child.shape[0] / parent.shape[0]\n",
        "        rw = r_child.shape[0] / parent.shape[0]\n",
        "        # Corrected the info gain formula\n",
        "        return self.entropy(parent) - (lw * self.entropy(l_child) + rw * self.entropy(r_child))\n",
        "\n",
        "    def entropy(self, y):\n",
        "        klasses = np.unique(y)\n",
        "        sum_entropy = 0 # Renamed sum to sum_entropy to avoid shadowing built-in sum\n",
        "        # Corrected 'kses' to 'klasses'\n",
        "        for k in klasses:\n",
        "            p = np.count_nonzero(y == k) / y.shape[0]\n",
        "            if p > 0: # Avoid log(0)\n",
        "                sum_entropy += -p * np.log2(p)\n",
        "\n",
        "        return sum_entropy\n",
        "\n",
        "\n",
        "    def split_data(self, dataset, feat_idx, threshold):\n",
        "        left = dataset[dataset[:, feat_idx] <= threshold]\n",
        "        right = dataset[dataset[:, feat_idx] > threshold]\n",
        "        return left, right\n",
        "\n",
        "    def major_class(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        idx = np.argmax(counts)\n",
        "        return classes[idx]\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        # Ensure y is a 2D array for concatenation\n",
        "        if y.ndim == 1:\n",
        "            y = y.reshape(-1, 1)\n",
        "        data = np.concatenate((x, y), axis=1)\n",
        "        self.tree = self.build_tree(data)\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Ensure x is treated as a numpy array\n",
        "        x = np.array(x)\n",
        "        return np.array([self.traverse_tree(x_i, self.tree) for x_i in x]).reshape(-1, 1)\n",
        "\n",
        "    def traverse_tree(self, x, node):\n",
        "        if node.klass is not None:\n",
        "            return node.klass\n",
        "        # Corrected the order of arguments in the recursive calls\n",
        "        if x[node.feat_idx] <= node.threshold:\n",
        "            return self.traverse_tree(x, node.left)\n",
        "        else:\n",
        "            return self.traverse_tree(x, node.right)\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\"\"):\n",
        "        if not tree:\n",
        "            tree = self.tree\n",
        "        if tree.klass is not None:\n",
        "            print(tree.klass)\n",
        "        else:\n",
        "            print(\"X_\" + str(tree.feat_idx), \"<=\", tree.threshold, \"?\")\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + \"  \") # Increased indent for clarity\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + \"  \") # Increased indent for clarity\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('/content/sample_data/Iris.csv')\n",
        "df = df.loc[:, df.columns != 'Id']\n",
        "\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the classifier\n",
        "classifier = DecisionTree(min_sample_sz=3, max_depth=4)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Print the tree\n",
        "classifier.print_tree()\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aktGzcvmtKQM",
        "outputId": "5f8a1cf3-a97f-4205-e840-22261061718d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_2 <= 1.9 ?\n",
            "left:Iris-setosa\n",
            "right:X_2 <= 4.7 ?\n",
            "  left:X_3 <= 1.6 ?\n",
            "    left:Iris-versicolor\n",
            "    right:Iris-virginica\n",
            "  right:X_3 <= 1.7 ?\n",
            "    left:X_2 <= 4.9 ?\n",
            "      left:Iris-versicolor\n",
            "      right:Iris-virginica\n",
            "    right:X_2 <= 4.8 ?\n",
            "      left:Iris-virginica\n",
            "      right:Iris-virginica\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}